---
title: "Video background extraction and moving object detection via conceptual beamforming algorithms"
collection: publications
category: manuscripts
permalink: /publication/Video background extraction and moving object detection via conceptual beamforming algorithms
excerpt: 'Video Background Extraction and Moving Object Detection (VBEMOD) correspond to most fundamental tasks in computer vision. In this paper, we for the first time explore the relationship between the sensor array beamformer and VBEMOD, and propose a novel Conceptual Beamforming Algorithm (CBA) for joint VBEMOD.'
date: 2025-05-01
venue: 'Digital Signal Processing'
slidesurl: ''
paperurl: '[http://academicpages.github.io/files/paper2.pdf](https://www.sciencedirect.com/science/article/pii/S1051200425000715)'
citation: 'Cheng, Z., Liang, J., Zhang, M., Sun, Z., & So, H. C. (2025). Video background extraction and moving object detection via conceptual beamforming algorithms. Digital Signal Processing, 160, 105049'
---

Video Background Extraction and Moving Object Detection (VBEMOD) correspond to most fundamental tasks in computer vision. In this paper, we for the first time explore the relationship between the sensor array beamformer and VBEMOD, and propose a novel Conceptual Beamforming Algorithm (CBA) for joint VBEMOD. First, we model the video image sequences as the snapshot signals received by a virtual sensor array via interchanging time and space domains, and consider the background and moving objects as the interested incoming signal and impulsive noise. Then, with the unit-element “steering vector”, the received signals with the impulsive noise removal is used to formulate a novel beamforming model for background extraction and moving object detection, which is jointly solved by alternating direction method of multipliers and fixed-point iteration. Besides, a solution based on the Lagrange programming neural network is derived to further improve the robustness of the proposed model in the presence of steering vector errors resulted from uncertain factors (e.g., varying illumination). Extensive experimental results on two public video datasets and ten benchmark methods consistently demonstrate the superiority of the proposed methods both visually and quantitatively.
